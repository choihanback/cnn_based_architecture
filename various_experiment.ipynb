{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "모듈 임포트 및 실험 변수 설정"
      ],
      "metadata": {
        "id": "tbZwPn92CZsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRzVXeluCYFf",
        "outputId": "c5f39c4c-8150-491a-d1ed-301e99c8a4f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_seed = 0\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "m5mN6iBuCnc_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "EPOCH = 100\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "6LCpsADtGOMY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 준비"
      ],
      "metadata": {
        "id": "lYN_mM1yGDCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_IMG_SIZE = 224\n",
        "CIFAR10_TRAIN_MEAN = (0.4914, 0.4822, 0.4465) # 원본 CIFAR-10 통계치\n",
        "CIFAR10_TRAIN_STD = (0.2470, 0.2435, 0.2616) # 원본 CIFAR-10 통계치\n",
        "\n",
        "# 기본 transform (업샘플링 + Tensor 변환 + 정규화)\n",
        "transform_upsampled = transforms.Compose([\n",
        "    transforms.Resize((TARGET_IMG_SIZE, TARGET_IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_TRAIN_MEAN, CIFAR10_TRAIN_STD)\n",
        "])\n",
        "\n",
        "# 기본 학습 데이터셋 (Augmentation 없음)\n",
        "train_DS = datasets.CIFAR10(\n",
        "    root = '/content/drive/MyDrive/Colab Notebooks/data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_upsampled\n",
        ")\n",
        "\n",
        "# 기본 테스트 데이터셋 (Augmentation 없음)\n",
        "test_DS = datasets.CIFAR10(\n",
        "    root = '/content/drive/MyDrive/Colab Notebooks/data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_upsampled\n",
        ")"
      ],
      "metadata": {
        "id": "LSDPBPFmFLpG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(random_seed)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "# 기본 학습 데이터로더 (Augmentation 미적용)\n",
        "train_DL = torch.utils.data.DataLoader(\n",
        "    train_DS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    generator=g,\n",
        "    worker_init_fn=seed_worker,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# 기본 테스트 데이터로더 (당연히 Augmentation 미적용)\n",
        "test_DL = torch.utils.data.DataLoader(\n",
        "    test_DS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    generator=g,\n",
        "    worker_init_fn=seed_worker,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "gQweZaPjS9HI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation용 transform (업샘플링 + Augmentation + Tensor 변환 + 정규화)\n",
        "transform_train_augmented_upsampled = transforms.Compose([\n",
        "    transforms.Resize((TARGET_IMG_SIZE, TARGET_IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # 50% 확률로 좌우 반전\n",
        "    transforms.RandomCrop(TARGET_IMG_SIZE, padding=int(TARGET_IMG_SIZE * 0.1), padding_mode='reflect'), # 10% 패딩 후 랜덤 크롭\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_TRAIN_MEAN, CIFAR10_TRAIN_STD),\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value='random')\n",
        "])\n",
        "\n",
        "# 위는 맨 처음에 내가 만든 Augmentation용 transform 코드\n",
        "\n",
        "\n",
        "\n",
        "# 아래는 2번째 실험방식 (실시간 증강을 그대로 적용하되, 일정확률로 원본 이미지 그대로를 학습하는 경우도 추가하는 방식)\n",
        "\n",
        "\n",
        "# # 1. 조건부로 적용할 증강 기법들을 정의합니다.\n",
        "# conditional_augmentations = transforms.Compose([\n",
        "#     transforms.RandomHorizontalFlip(p=0.5), # 이 블록이 적용될 때, 내부적으로 50% 확률로 반전\n",
        "#     transforms.RandomCrop(TARGET_IMG_SIZE, padding=int(TARGET_IMG_SIZE * 0.1), padding_mode='reflect')\n",
        "# ])\n",
        "\n",
        "# # 2. 새로운 학습용 transform 파이프라인 정의\n",
        "# #    예: 50% 확률로 conditional_augmentations를 적용하고, 50% 확률로는 적용하지 않음 (Resize만 된 상태)\n",
        "\n",
        "# transform_train_augmented_upsampled = transforms.Compose([\n",
        "#     # 항상 적용되는 초기 Resize\n",
        "#     transforms.Resize((TARGET_IMG_SIZE, TARGET_IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "#     # conditional_augmentations 블록 전체를 prob_apply_conditional_augs 확률로 적용\n",
        "#     transforms.RandomApply(\n",
        "#         # RandomApply는 nn.Module로 구성된 리스트를 받는 것이 일반적이지만,\n",
        "#         # transforms 객체들의 리스트를 직접 사용할 수도 있습니다.\n",
        "#         # 여기서는 Compose 객체 하나를 리스트에 넣어 전달합니다.\n",
        "#         [conditional_augmentations],\n",
        "#         p=0.2\n",
        "#     ),\n",
        "#     # 항상 적용되는 최종 변환\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(CIFAR10_TRAIN_MEAN, CIFAR10_TRAIN_STD)\n",
        "# ])\n",
        "\n",
        "\n",
        "# --------------------------------------------------------2번째 실험방식 끝--------------------------------------------------\n",
        "\n",
        "# Augmentation용 학습 데이터셋 (Augmentation 적용)\n",
        "train_DS_augmented = datasets.CIFAR10(\n",
        "    root = '/content/drive/MyDrive/Colab Notebooks/data', # 데이터 저장 경로\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train_augmented_upsampled # Augmentation용 transform 사용\n",
        ")\n",
        "\n",
        "# Augmentation용 학습 데이터로더 (Augmentation 적용)\n",
        "train_DL_augmented = torch.utils.data.DataLoader(\n",
        "    train_DS_augmented,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    generator=g,\n",
        "    worker_init_fn=seed_worker,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "RDXtH58cXCCM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training samples: {len(train_DS)}\")\n",
        "print(f\"Number of test samples: {len(test_DS)}\")\n",
        "print(f\"Shape of one training sample: {train_DS[0][0].shape}\")\n",
        "print(f\"Data type of one training sample: {train_DS[0][0].dtype}\")\n",
        "print(f\"Label of one training sample: {train_DS[0][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEKVIdlzKgcr",
        "outputId": "4723512c-6883-4662-b104-04c65fb5ed39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 50000\n",
            "Number of test samples: 10000\n",
            "Shape of one training sample: torch.Size([3, 224, 224])\n",
            "Data type of one training sample: torch.float32\n",
            "Label of one training sample: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet"
      ],
      "metadata": {
        "id": "gDUjlByyKixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  # 첫번째 Conv\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),           # 두번째 Conv\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),          # 세번째 Conv\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),          # 네번째 Conv\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),          # 다섯번째 Conv\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))                 # Adaptive Pooling\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                           # Fully Connected 1\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),                                  # Fully Connected 2\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),                           # 출력층\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rsmk4m6JKJh7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train & Test Function"
      ],
      "metadata": {
        "id": "wvEG90mPTSa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train(model, train_DL, criterion):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    loss_history=[]\n",
        "    acc_history=[]\n",
        "\n",
        "    NoT = len(train_DL.dataset)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for ep in range(EPOCH):\n",
        "        rloss = 0\n",
        "        rcorrect = 0\n",
        "\n",
        "        for x_batch, y_batch in train_DL:\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "\n",
        "            y_hat = model(x_batch)\n",
        "            loss = criterion(y_hat, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # # 임시\n",
        "            # print(\"Gradient of first conv layer weight:\", model.features[0].weight.grad)\n",
        "            # if model.features[0].weight.grad is not None:\n",
        "            #     print(\"Mean absolute grad of first conv layer:\", model.features[0].weight.grad.abs().mean().item())\n",
        "            # if model.features[10].weight.grad is not None:\n",
        "            #     print(\"Mean abs grad of Block 3 first conv:\", model.features[10].weight.grad.abs().mean().item())\n",
        "            # else:\n",
        "            #     print(\"Grad of Block 3 first conv is None\")\n",
        "            #     print(\"Gradient of last linear layer weight:\", model.classifier[6].weight.grad)\n",
        "            # if model.classifier[6].weight.grad is not None:\n",
        "            #     print(\"Mean absolute grad of last linear layer:\", model.classifier[6].weight.grad.abs().mean().item())\n",
        "            # # 임시\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_b = loss.item() * x_batch.shape[0]\n",
        "            rloss += loss_b\n",
        "            pred = y_hat.argmax(dim=1)\n",
        "            corrects_b = torch.sum(pred == y_batch).item()\n",
        "            rcorrect += corrects_b\n",
        "\n",
        "        loss_e = rloss/NoT\n",
        "        accuracy_e = rcorrect/NoT * 100\n",
        "        loss_history += [loss_e]\n",
        "        acc_history += [accuracy_e]\n",
        "        print(f\"Epoch: {ep+1}, train loss: {round(loss_e,3)}, train accuracy: {round(accuracy_e,1)} %\")\n",
        "        print(\"-\"*20)\n",
        "\n",
        "    return loss_history, acc_history"
      ],
      "metadata": {
        "id": "AS4AT2LoTRdg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Test(model,test_DL):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        rcorrect = 0\n",
        "        for x_batch, y_batch in test_DL:\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            y_hat = model(x_batch)\n",
        "            pred = y_hat.argmax(dim=1)\n",
        "            corrects_b = torch.sum(pred == y_batch).item()\n",
        "            rcorrect += corrects_b\n",
        "        accuracy_e = rcorrect/len(test_DL.dataset)*100\n",
        "    print(f\"Test accuracy: {rcorrect}/{len(test_DL.dataset)} ({round(accuracy_e,1)} %)\")\n",
        "    return round(accuracy_e,1)"
      ],
      "metadata": {
        "id": "YOh5aMhQWqI1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실험 1**: Data Augmentation 성능 확인 (in AlexNet)"
      ],
      "metadata": {
        "id": "WSDbr0RUYmSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_no_aug=AlexNet().to(DEVICE)\n",
        "print(model_no_aug)\n",
        "x_batch, _ = next(iter(train_DL))\n",
        "print(model_no_aug(x_batch.to(DEVICE)).shape)\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\" Data Augmentation 적용하지 않은 상태로 AlexNet 학습\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "loss_history_no_aug, acc_history_no_aug = Train(model_no_aug, train_DL, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crmvgOlyYt4I",
        "outputId": "96cd34a8-2b91-43bb-e1eb-2438ade79d25"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 10])\n",
            "==============================\n",
            " Data Augmentation 적용하지 않은 상태로 AlexNet 학습\n",
            "==============================\n",
            "Epoch: 1, train loss: 1.839, train accuracy: 30.9 %\n",
            "--------------------\n",
            "Epoch: 2, train loss: 1.498, train accuracy: 44.9 %\n",
            "--------------------\n",
            "Epoch: 3, train loss: 1.359, train accuracy: 50.7 %\n",
            "--------------------\n",
            "Epoch: 4, train loss: 1.273, train accuracy: 54.5 %\n",
            "--------------------\n",
            "Epoch: 5, train loss: 1.181, train accuracy: 57.9 %\n",
            "--------------------\n",
            "Epoch: 6, train loss: 1.117, train accuracy: 60.2 %\n",
            "--------------------\n",
            "Epoch: 7, train loss: 1.057, train accuracy: 62.4 %\n",
            "--------------------\n",
            "Epoch: 8, train loss: 1.019, train accuracy: 63.8 %\n",
            "--------------------\n",
            "Epoch: 9, train loss: 0.972, train accuracy: 65.7 %\n",
            "--------------------\n",
            "Epoch: 10, train loss: 0.947, train accuracy: 66.5 %\n",
            "--------------------\n",
            "Epoch: 11, train loss: 0.911, train accuracy: 67.5 %\n",
            "--------------------\n",
            "Epoch: 12, train loss: 0.884, train accuracy: 68.8 %\n",
            "--------------------\n",
            "Epoch: 13, train loss: 0.855, train accuracy: 69.7 %\n",
            "--------------------\n",
            "Epoch: 14, train loss: 0.821, train accuracy: 71.0 %\n",
            "--------------------\n",
            "Epoch: 15, train loss: 0.793, train accuracy: 71.8 %\n",
            "--------------------\n",
            "Epoch: 16, train loss: 0.773, train accuracy: 72.9 %\n",
            "--------------------\n",
            "Epoch: 17, train loss: 0.746, train accuracy: 74.0 %\n",
            "--------------------\n",
            "Epoch: 18, train loss: 0.723, train accuracy: 74.7 %\n",
            "--------------------\n",
            "Epoch: 19, train loss: 0.701, train accuracy: 75.4 %\n",
            "--------------------\n",
            "Epoch: 20, train loss: 0.676, train accuracy: 76.2 %\n",
            "--------------------\n",
            "Epoch: 21, train loss: 0.644, train accuracy: 77.3 %\n",
            "--------------------\n",
            "Epoch: 22, train loss: 0.625, train accuracy: 78.2 %\n",
            "--------------------\n",
            "Epoch: 23, train loss: 0.603, train accuracy: 79.1 %\n",
            "--------------------\n",
            "Epoch: 24, train loss: 0.58, train accuracy: 79.8 %\n",
            "--------------------\n",
            "Epoch: 25, train loss: 0.565, train accuracy: 80.6 %\n",
            "--------------------\n",
            "Epoch: 26, train loss: 0.527, train accuracy: 81.9 %\n",
            "--------------------\n",
            "Epoch: 27, train loss: 0.504, train accuracy: 82.6 %\n",
            "--------------------\n",
            "Epoch: 28, train loss: 0.476, train accuracy: 83.7 %\n",
            "--------------------\n",
            "Epoch: 29, train loss: 0.488, train accuracy: 83.4 %\n",
            "--------------------\n",
            "Epoch: 30, train loss: 0.451, train accuracy: 84.8 %\n",
            "--------------------\n",
            "Epoch: 31, train loss: 0.442, train accuracy: 85.0 %\n",
            "--------------------\n",
            "Epoch: 32, train loss: 0.429, train accuracy: 85.4 %\n",
            "--------------------\n",
            "Epoch: 33, train loss: 0.4, train accuracy: 86.4 %\n",
            "--------------------\n",
            "Epoch: 34, train loss: 0.4, train accuracy: 86.5 %\n",
            "--------------------\n",
            "Epoch: 35, train loss: 0.39, train accuracy: 86.9 %\n",
            "--------------------\n",
            "Epoch: 36, train loss: 0.364, train accuracy: 87.7 %\n",
            "--------------------\n",
            "Epoch: 37, train loss: 0.356, train accuracy: 88.1 %\n",
            "--------------------\n",
            "Epoch: 38, train loss: 0.346, train accuracy: 88.7 %\n",
            "--------------------\n",
            "Epoch: 39, train loss: 0.345, train accuracy: 88.7 %\n",
            "--------------------\n",
            "Epoch: 40, train loss: 0.329, train accuracy: 89.0 %\n",
            "--------------------\n",
            "Epoch: 41, train loss: 0.322, train accuracy: 89.4 %\n",
            "--------------------\n",
            "Epoch: 42, train loss: 0.309, train accuracy: 89.6 %\n",
            "--------------------\n",
            "Epoch: 43, train loss: 0.306, train accuracy: 89.9 %\n",
            "--------------------\n",
            "Epoch: 44, train loss: 0.306, train accuracy: 90.0 %\n",
            "--------------------\n",
            "Epoch: 45, train loss: 0.293, train accuracy: 90.4 %\n",
            "--------------------\n",
            "Epoch: 46, train loss: 0.284, train accuracy: 90.9 %\n",
            "--------------------\n",
            "Epoch: 47, train loss: 0.29, train accuracy: 90.7 %\n",
            "--------------------\n",
            "Epoch: 48, train loss: 0.279, train accuracy: 91.0 %\n",
            "--------------------\n",
            "Epoch: 49, train loss: 0.274, train accuracy: 91.1 %\n",
            "--------------------\n",
            "Epoch: 50, train loss: 0.261, train accuracy: 91.6 %\n",
            "--------------------\n",
            "Epoch: 51, train loss: 0.268, train accuracy: 91.4 %\n",
            "--------------------\n",
            "Epoch: 52, train loss: 0.27, train accuracy: 91.4 %\n",
            "--------------------\n",
            "Epoch: 53, train loss: 0.249, train accuracy: 92.1 %\n",
            "--------------------\n",
            "Epoch: 54, train loss: 0.245, train accuracy: 92.3 %\n",
            "--------------------\n",
            "Epoch: 55, train loss: 0.248, train accuracy: 92.2 %\n",
            "--------------------\n",
            "Epoch: 56, train loss: 0.249, train accuracy: 92.2 %\n",
            "--------------------\n",
            "Epoch: 57, train loss: 0.248, train accuracy: 92.2 %\n",
            "--------------------\n",
            "Epoch: 58, train loss: 0.235, train accuracy: 92.6 %\n",
            "--------------------\n",
            "Epoch: 59, train loss: 0.232, train accuracy: 92.8 %\n",
            "--------------------\n",
            "Epoch: 60, train loss: 0.242, train accuracy: 92.5 %\n",
            "--------------------\n",
            "Epoch: 61, train loss: 0.228, train accuracy: 92.9 %\n",
            "--------------------\n",
            "Epoch: 62, train loss: 0.226, train accuracy: 93.0 %\n",
            "--------------------\n",
            "Epoch: 63, train loss: 0.232, train accuracy: 92.8 %\n",
            "--------------------\n",
            "Epoch: 64, train loss: 0.234, train accuracy: 92.8 %\n",
            "--------------------\n",
            "Epoch: 65, train loss: 0.227, train accuracy: 93.1 %\n",
            "--------------------\n",
            "Epoch: 66, train loss: 0.217, train accuracy: 93.3 %\n",
            "--------------------\n",
            "Epoch: 67, train loss: 0.21, train accuracy: 93.5 %\n",
            "--------------------\n",
            "Epoch: 68, train loss: 0.222, train accuracy: 93.3 %\n",
            "--------------------\n",
            "Epoch: 69, train loss: 0.216, train accuracy: 93.3 %\n",
            "--------------------\n",
            "Epoch: 70, train loss: 0.215, train accuracy: 93.4 %\n",
            "--------------------\n",
            "Epoch: 71, train loss: 0.212, train accuracy: 93.7 %\n",
            "--------------------\n",
            "Epoch: 72, train loss: 0.23, train accuracy: 93.3 %\n",
            "--------------------\n",
            "Epoch: 73, train loss: 0.219, train accuracy: 93.4 %\n",
            "--------------------\n",
            "Epoch: 74, train loss: 0.204, train accuracy: 93.9 %\n",
            "--------------------\n",
            "Epoch: 75, train loss: 0.204, train accuracy: 93.8 %\n",
            "--------------------\n",
            "Epoch: 76, train loss: 0.208, train accuracy: 93.9 %\n",
            "--------------------\n",
            "Epoch: 77, train loss: 0.197, train accuracy: 94.1 %\n",
            "--------------------\n",
            "Epoch: 78, train loss: 0.209, train accuracy: 93.8 %\n",
            "--------------------\n",
            "Epoch: 79, train loss: 0.245, train accuracy: 92.8 %\n",
            "--------------------\n",
            "Epoch: 80, train loss: 0.181, train accuracy: 94.6 %\n",
            "--------------------\n",
            "Epoch: 81, train loss: 0.184, train accuracy: 94.6 %\n",
            "--------------------\n",
            "Epoch: 82, train loss: 0.205, train accuracy: 94.1 %\n",
            "--------------------\n",
            "Epoch: 83, train loss: 0.209, train accuracy: 93.9 %\n",
            "--------------------\n",
            "Epoch: 84, train loss: 0.206, train accuracy: 94.1 %\n",
            "--------------------\n",
            "Epoch: 85, train loss: 0.192, train accuracy: 94.3 %\n",
            "--------------------\n",
            "Epoch: 86, train loss: 0.198, train accuracy: 94.2 %\n",
            "--------------------\n",
            "Epoch: 87, train loss: 0.182, train accuracy: 94.7 %\n",
            "--------------------\n",
            "Epoch: 88, train loss: 0.189, train accuracy: 94.5 %\n",
            "--------------------\n",
            "Epoch: 89, train loss: 0.185, train accuracy: 94.6 %\n",
            "--------------------\n",
            "Epoch: 90, train loss: 0.202, train accuracy: 94.3 %\n",
            "--------------------\n",
            "Epoch: 91, train loss: 0.192, train accuracy: 94.6 %\n",
            "--------------------\n",
            "Epoch: 92, train loss: 0.189, train accuracy: 94.6 %\n",
            "--------------------\n",
            "Epoch: 93, train loss: 0.205, train accuracy: 94.3 %\n",
            "--------------------\n",
            "Epoch: 94, train loss: 0.185, train accuracy: 94.9 %\n",
            "--------------------\n",
            "Epoch: 95, train loss: 0.181, train accuracy: 94.8 %\n",
            "--------------------\n",
            "Epoch: 96, train loss: 0.196, train accuracy: 94.5 %\n",
            "--------------------\n",
            "Epoch: 97, train loss: 0.184, train accuracy: 94.8 %\n",
            "--------------------\n",
            "Epoch: 98, train loss: 0.176, train accuracy: 94.9 %\n",
            "--------------------\n",
            "Epoch: 99, train loss: 0.187, train accuracy: 94.7 %\n",
            "--------------------\n",
            "Epoch: 100, train loss: 0.182, train accuracy: 94.9 %\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"Data Augmentation 적용하지 않은 AlexNet 테스트\")\n",
        "print(\"=\"*30)\n",
        "# Test 함수로 평가\n",
        "test_accuracy_no_aug = Test(model_no_aug, test_DL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BG1rt4NZu7Y",
        "outputId": "b365eb4e-f808-4569-ee36-8d48c63fea27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Data Augmentation 적용하지 않은 AlexNet 테스트\n",
            "==============================\n",
            "Test accuracy: 6940/10000 (69.4 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_aug=AlexNet().to(DEVICE)\n",
        "print(model_aug)\n",
        "x_batch, _ = next(iter(train_DL_augmented))\n",
        "print(model_aug(x_batch.to(DEVICE)).shape)\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"실험 1: Data Augmentation 적용한 상태로 AlexNet 학습\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "loss_history_aug, acc_history_aug = Train(model_aug, train_DL_augmented, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSb17ubxaP6t",
        "outputId": "2e42beb2-f1bc-41c6-b1a5-bb391a3e66bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 10])\n",
            "==============================\n",
            "실험 1: Data Augmentation 적용한 상태로 AlexNet 학습\n",
            "==============================\n",
            "Epoch: 1, train loss: 1.846, train accuracy: 31.4 %\n",
            "--------------------\n",
            "Epoch: 2, train loss: 1.565, train accuracy: 42.8 %\n",
            "--------------------\n",
            "Epoch: 3, train loss: 1.471, train accuracy: 47.0 %\n",
            "--------------------\n",
            "Epoch: 4, train loss: 1.399, train accuracy: 49.8 %\n",
            "--------------------\n",
            "Epoch: 5, train loss: 1.342, train accuracy: 52.0 %\n",
            "--------------------\n",
            "Epoch: 6, train loss: 1.302, train accuracy: 53.6 %\n",
            "--------------------\n",
            "Epoch: 7, train loss: 1.271, train accuracy: 54.9 %\n",
            "--------------------\n",
            "Epoch: 8, train loss: 1.23, train accuracy: 56.8 %\n",
            "--------------------\n",
            "Epoch: 9, train loss: 1.205, train accuracy: 57.5 %\n",
            "--------------------\n",
            "Epoch: 10, train loss: 1.196, train accuracy: 57.7 %\n",
            "--------------------\n",
            "Epoch: 11, train loss: 1.182, train accuracy: 58.3 %\n",
            "--------------------\n",
            "Epoch: 12, train loss: 1.174, train accuracy: 58.8 %\n",
            "--------------------\n",
            "Epoch: 13, train loss: 1.15, train accuracy: 59.8 %\n",
            "--------------------\n",
            "Epoch: 14, train loss: 1.134, train accuracy: 60.2 %\n",
            "--------------------\n",
            "Epoch: 15, train loss: 1.132, train accuracy: 60.5 %\n",
            "--------------------\n",
            "Epoch: 16, train loss: 1.125, train accuracy: 60.7 %\n",
            "--------------------\n",
            "Epoch: 17, train loss: 1.114, train accuracy: 61.3 %\n",
            "--------------------\n",
            "Epoch: 18, train loss: 1.103, train accuracy: 61.6 %\n",
            "--------------------\n",
            "Epoch: 19, train loss: 1.101, train accuracy: 61.5 %\n",
            "--------------------\n",
            "Epoch: 20, train loss: 1.082, train accuracy: 62.5 %\n",
            "--------------------\n",
            "Epoch: 21, train loss: 1.073, train accuracy: 62.6 %\n",
            "--------------------\n",
            "Epoch: 22, train loss: 1.072, train accuracy: 62.8 %\n",
            "--------------------\n",
            "Epoch: 23, train loss: 1.067, train accuracy: 63.1 %\n",
            "--------------------\n",
            "Epoch: 24, train loss: 1.059, train accuracy: 63.3 %\n",
            "--------------------\n",
            "Epoch: 25, train loss: 1.041, train accuracy: 63.9 %\n",
            "--------------------\n",
            "Epoch: 26, train loss: 1.044, train accuracy: 63.8 %\n",
            "--------------------\n",
            "Epoch: 27, train loss: 1.037, train accuracy: 64.3 %\n",
            "--------------------\n",
            "Epoch: 28, train loss: 1.032, train accuracy: 64.4 %\n",
            "--------------------\n",
            "Epoch: 29, train loss: 1.018, train accuracy: 64.7 %\n",
            "--------------------\n",
            "Epoch: 30, train loss: 1.011, train accuracy: 65.1 %\n",
            "--------------------\n",
            "Epoch: 31, train loss: 1.014, train accuracy: 64.9 %\n",
            "--------------------\n",
            "Epoch: 32, train loss: 1.002, train accuracy: 65.6 %\n",
            "--------------------\n",
            "Epoch: 33, train loss: 1.015, train accuracy: 64.8 %\n",
            "--------------------\n",
            "Epoch: 34, train loss: 1.011, train accuracy: 65.2 %\n",
            "--------------------\n",
            "Epoch: 35, train loss: 0.995, train accuracy: 66.0 %\n",
            "--------------------\n",
            "Epoch: 36, train loss: 0.991, train accuracy: 66.1 %\n",
            "--------------------\n",
            "Epoch: 37, train loss: 0.986, train accuracy: 66.1 %\n",
            "--------------------\n",
            "Epoch: 38, train loss: 0.993, train accuracy: 65.8 %\n",
            "--------------------\n",
            "Epoch: 39, train loss: 0.977, train accuracy: 66.6 %\n",
            "--------------------\n",
            "Epoch: 40, train loss: 0.977, train accuracy: 66.3 %\n",
            "--------------------\n",
            "Epoch: 41, train loss: 0.971, train accuracy: 66.7 %\n",
            "--------------------\n",
            "Epoch: 42, train loss: 1.003, train accuracy: 65.7 %\n",
            "--------------------\n",
            "Epoch: 43, train loss: 1.018, train accuracy: 65.4 %\n",
            "--------------------\n",
            "Epoch: 44, train loss: 1.046, train accuracy: 64.1 %\n",
            "--------------------\n",
            "Epoch: 45, train loss: 0.967, train accuracy: 66.8 %\n",
            "--------------------\n",
            "Epoch: 46, train loss: 0.972, train accuracy: 66.8 %\n",
            "--------------------\n",
            "Epoch: 47, train loss: 0.952, train accuracy: 67.5 %\n",
            "--------------------\n",
            "Epoch: 48, train loss: 0.957, train accuracy: 67.4 %\n",
            "--------------------\n",
            "Epoch: 49, train loss: 1.049, train accuracy: 64.2 %\n",
            "--------------------\n",
            "Epoch: 50, train loss: 1.003, train accuracy: 65.7 %\n",
            "--------------------\n",
            "Epoch: 51, train loss: 0.96, train accuracy: 67.1 %\n",
            "--------------------\n",
            "Epoch: 52, train loss: 0.957, train accuracy: 67.5 %\n",
            "--------------------\n",
            "Epoch: 53, train loss: 0.962, train accuracy: 67.5 %\n",
            "--------------------\n",
            "Epoch: 54, train loss: 0.945, train accuracy: 67.8 %\n",
            "--------------------\n",
            "Epoch: 55, train loss: 0.948, train accuracy: 67.4 %\n",
            "--------------------\n",
            "Epoch: 56, train loss: 0.935, train accuracy: 68.3 %\n",
            "--------------------\n",
            "Epoch: 57, train loss: 0.953, train accuracy: 67.7 %\n",
            "--------------------\n",
            "Epoch: 58, train loss: 0.947, train accuracy: 67.9 %\n",
            "--------------------\n",
            "Epoch: 59, train loss: 0.924, train accuracy: 68.5 %\n",
            "--------------------\n",
            "Epoch: 60, train loss: 0.948, train accuracy: 67.9 %\n",
            "--------------------\n",
            "Epoch: 61, train loss: 0.954, train accuracy: 67.7 %\n",
            "--------------------\n",
            "Epoch: 62, train loss: 0.961, train accuracy: 67.5 %\n",
            "--------------------\n",
            "Epoch: 63, train loss: 0.934, train accuracy: 68.4 %\n",
            "--------------------\n",
            "Epoch: 64, train loss: 0.944, train accuracy: 68.0 %\n",
            "--------------------\n",
            "Epoch: 65, train loss: 0.919, train accuracy: 68.7 %\n",
            "--------------------\n",
            "Epoch: 66, train loss: 0.936, train accuracy: 68.2 %\n",
            "--------------------\n",
            "Epoch: 67, train loss: 0.934, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 68, train loss: 0.951, train accuracy: 67.7 %\n",
            "--------------------\n",
            "Epoch: 69, train loss: 0.928, train accuracy: 68.5 %\n",
            "--------------------\n",
            "Epoch: 70, train loss: 0.958, train accuracy: 67.4 %\n",
            "--------------------\n",
            "Epoch: 71, train loss: 0.929, train accuracy: 68.4 %\n",
            "--------------------\n",
            "Epoch: 72, train loss: 0.932, train accuracy: 68.2 %\n",
            "--------------------\n",
            "Epoch: 73, train loss: 0.919, train accuracy: 68.9 %\n",
            "--------------------\n",
            "Epoch: 74, train loss: 0.929, train accuracy: 68.4 %\n",
            "--------------------\n",
            "Epoch: 75, train loss: 0.929, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 76, train loss: 0.916, train accuracy: 69.0 %\n",
            "--------------------\n",
            "Epoch: 77, train loss: 0.926, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 78, train loss: 0.93, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 79, train loss: 0.926, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 80, train loss: 0.94, train accuracy: 68.2 %\n",
            "--------------------\n",
            "Epoch: 81, train loss: 0.94, train accuracy: 68.1 %\n",
            "--------------------\n",
            "Epoch: 82, train loss: 0.934, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 83, train loss: 0.932, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 84, train loss: 0.971, train accuracy: 67.7 %\n",
            "--------------------\n",
            "Epoch: 85, train loss: 0.93, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 86, train loss: 0.935, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 87, train loss: 0.918, train accuracy: 69.1 %\n",
            "--------------------\n",
            "Epoch: 88, train loss: 0.914, train accuracy: 69.3 %\n",
            "--------------------\n",
            "Epoch: 89, train loss: 0.92, train accuracy: 69.2 %\n",
            "--------------------\n",
            "Epoch: 90, train loss: 0.921, train accuracy: 68.9 %\n",
            "--------------------\n",
            "Epoch: 91, train loss: 0.934, train accuracy: 68.7 %\n",
            "--------------------\n",
            "Epoch: 92, train loss: 0.918, train accuracy: 69.1 %\n",
            "--------------------\n",
            "Epoch: 93, train loss: 0.913, train accuracy: 69.2 %\n",
            "--------------------\n",
            "Epoch: 94, train loss: 0.929, train accuracy: 68.6 %\n",
            "--------------------\n",
            "Epoch: 95, train loss: 1.2, train accuracy: 61.0 %\n",
            "--------------------\n",
            "Epoch: 96, train loss: 1.043, train accuracy: 65.0 %\n",
            "--------------------\n",
            "Epoch: 97, train loss: 0.979, train accuracy: 67.1 %\n",
            "--------------------\n",
            "Epoch: 98, train loss: 0.957, train accuracy: 67.7 %\n",
            "--------------------\n",
            "Epoch: 99, train loss: 0.931, train accuracy: 68.8 %\n",
            "--------------------\n",
            "Epoch: 100, train loss: 0.911, train accuracy: 69.3 %\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"Data Augmentation 적용한 AlexNet 테스트\")\n",
        "print(\"=\"*30)\n",
        "# Test 함수로 평가\n",
        "test_accuracy_aug = Test(model_aug, test_DL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXUyFKBHaWG1",
        "outputId": "49733eda-ac0d-42f5-efbe-ce255bd197b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Data Augmentation 적용한 AlexNet 테스트\n",
            "==============================\n",
            "Test accuracy: 7711/10000 (77.1 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에폭 범위 (X축으로 사용)\n",
        "epochs_range = range(1, EPOCH + 1)\n",
        "\n",
        "# 전체 그림(figure)의 크기를 설정합니다. (플롯 2개용으로 너비 조정)\n",
        "plt.figure(figsize=(15, 6)) # 이전보다 너비를 약간 줄여도 괜찮습니다.\n",
        "\n",
        "# 1. 학습 정확도(Training Accuracy) 비교\n",
        "plt.subplot(1, 2, 1) # 1행 2열의 첫 번째 플롯\n",
        "plt.plot(epochs_range, acc_history_no_aug, marker='o', linestyle='-', label='No Augmentation')\n",
        "plt.plot(epochs_range, acc_history_aug, marker='x', linestyle='--', label='With Augmentation')\n",
        "plt.title('AlexNet Training Accuracy Comparison', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True)\n",
        "\n",
        "# 2. 최종 테스트 정확도(Final Test Accuracy) 비교 (막대 그래프)\n",
        "plt.subplot(1, 2, 2) # 1행 2열의 두 번째 플롯\n",
        "labels = ['No Augmentation', 'With Augmentation']\n",
        "test_accuracies = [test_accuracy_no_aug, test_accuracy_aug]\n",
        "\n",
        "bars = plt.bar(labels, test_accuracies, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('AlexNet Test Accuracy Comparison', fontsize=14)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.ylim(0, 100) # Y축 범위를 0에서 100으로 설정 (정확도는 백분율)\n",
        "\n",
        "# 각 막대 위에 정확도 값을 표시합니다.\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1.0, f'{yval:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# 플롯들이 겹치지 않도록 레이아웃을 조정합니다.\n",
        "plt.tight_layout()\n",
        "# 플롯을 화면에 표시합니다.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "LldFHEHUeSck",
        "outputId": "72ddb272-c242-438a-e8bd-b30823667dd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실험 2:** 3x3 Convolution 3번 vs 7x7 Convolution 1번 (in VGG16)    "
      ],
      "metadata": {
        "id": "El8m4drQlAmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16_3x3(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16_3x3, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 14 -> 7\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096), # Block 5의 마지막 Conv2d 출력 채널은 512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "M84hyTV7DJR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16_7x7(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16_7x7, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=7, padding=3), # 원본 VGG 16과 다르게, 3x3 conv 3번 -> 7x7 conv 1번으로 변경\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=7, padding=3),  # 원본 VGG 16과 다르게, 3x3 conv 3번 -> 7x7 conv 1번으로 변경\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=7, padding=3),  # 원본 VGG 16과 다르게, 3x3 conv 3번 -> 7x7 conv 1번으로 변경\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 7 -> 7\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096), # Block 5의 마지막 Conv2d 출력 채널은 512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sKb5yTUSk_YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"표준 VGG16 모델 학습 (3x3 Convolution만 이용)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "model_vgg16_3x3 = VGG16_3x3().to(DEVICE) # 이전에 정의한 표준 VGG16 클래스\n",
        "print(model_vgg16_3x3)\n",
        "\n",
        "# 1. 파라미터 수 계산\n",
        "total_params_3x3 = sum(p.numel() for p in model_vgg16_3x3.parameters() if p.requires_grad)\n",
        "print(f\"\\n표준 VGG16 파라미터 수: {total_params_3x3:,}\")\n",
        "\n",
        "# 2. 학습 연산 시간 측정\n",
        "print(f\"\\n\\n학습 시작\")\n",
        "start_time_3x3 = time.time()\n",
        "loss_history_3x3, acc_history_3x3 = Train(model_vgg16_3x3, train_DL, criterion)\n",
        "end_time_3x3 = time.time()\n",
        "training_time_3x3 = end_time_3x3 - start_time_3x3\n",
        "print(f\"\\nVGG16_3x3 총 학습 시간: {training_time_3x3:.2f} 초\")\n",
        "\n",
        "# 3. 분류 성능 평가\n",
        "print(\"\\nVGG16_3x3 테스트\")\n",
        "test_accuracy_3x3 = Test(model_vgg16_3x3, test_DL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UYkqlNPtBiH",
        "outputId": "067bcc0f-ed50-4b59-cc62-61ac9e4f4a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "표준 VGG16 모델 학습 (3x3 Convolution만 이용)\n",
            "==============================\n",
            "VGG16(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "표준 VGG16 파라미터 수: 134,301,514\n",
            "\n",
            "\n",
            "학습 시작\n",
            "Epoch: 1, train loss: 2.304, train accuracy: 9.8 %\n",
            "--------------------\n",
            "Epoch: 2, train loss: 2.303, train accuracy: 10.0 %\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"7*7 Convolution으로 Custom한 VGG16 모델 학습 (3,4,5번째 블록만 변경)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "model_vgg16_7x7 = VGG16_7x7().to(DEVICE) # 이전에 정의한 표준 VGG16 클래스\n",
        "print(model_vgg16_7x7)\n",
        "\n",
        "# 1. 파라미터 수 계산\n",
        "total_params_7x7 = sum(p.numel() for p in model_vgg16_7x7.parameters() if p.requires_grad)\n",
        "print(f\"\\n표준 VGG16 파라미터 수: {total_params_7x7:,}\")\n",
        "\n",
        "# 2. 학습 연산 시간 측정\n",
        "print(f\"\\n\\n학습 시작\")\n",
        "start_time_7x7 = time.time()\n",
        "loss_history_7x7, acc_history_7x7 = Train(model_vgg16_7x7, train_DL, criterion)\n",
        "end_time_7x7 = time.time()\n",
        "training_time_7x7 = end_time_7x7 - start_time_7x7\n",
        "print(f\"\\nVGG16_7x7 총 학습 시간: {training_time_7x7:.2f} 초\")\n",
        "\n",
        "# 3. 분류 성능 평가\n",
        "print(\"\\nVGG16_7x7 테스트\")\n",
        "test_accuracy_7x7 = Test(model_vgg16_7x7, test_DL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ihXWAyAzvQHo",
        "outputId": "a7d675db-ab6b-49c7-fea6-7d55502850ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "7*7 Convolution으로 Custom한 VGG16 모델 학습 (3,4,5번째 블록만 변경)\n",
            "==============================\n",
            "VGG16_7x7(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (13): Conv2d(256, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "표준 VGG16 파라미터 수: 140,721,482\n",
            "\n",
            "\n",
            "학습 시작\n",
            "Epoch: 1, train loss: 1.784, train accuracy: 35.4 %\n",
            "--------------------\n",
            "Epoch: 2, train loss: 1.364, train accuracy: 51.1 %\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6f7a0f1b29f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n학습 시작\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstart_time_7x7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss_history_7x7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_history_7x7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_vgg16_7x7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_DL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mend_time_7x7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtraining_time_7x7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time_7x7\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_7x7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-68fcb6579d1a>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(model, train_DL, criterion)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mrloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 플롯 생성\n",
        "epochs_range = range(1, EPOCH + 1)\n",
        "model_labels = ['VGG16 (3x3 Conv)', 'VGG16 (7x7 Conv Customization)']\n",
        "\n",
        "plt.figure(figsize=(18, 12)) # 4개의 플롯을 위한 크기 조정\n",
        "\n",
        "# 1. 파라미터 수 비교\n",
        "plt.subplot(2, 2, 1)\n",
        "params_values = [total_params_3x3, total_params_7x7]\n",
        "bars_params = plt.bar(model_labels, params_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('모델 파라미터 수 비교', fontsize=14)\n",
        "plt.ylabel('파라미터 수', fontsize=12)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_params:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + max(params_values)*0.01, f'{int(yval):,}', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 2. 학습 시간 비교\n",
        "plt.subplot(2, 2, 2)\n",
        "time_values = [training_time_3x3, training_time_7x7]\n",
        "bars_time = plt.bar(model_labels, time_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('Train Time Comparison', fontsize=14)\n",
        "plt.ylabel('시간 (sec)', fontsize=12)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_time:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + max(time_values)*0.01, f'{yval:.2f}s', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 3. 에폭별 학습 정확도 비교\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs_range, acc_history_3x3, marker='o', linestyle='-', label='VGG16 (3x3 Conv)')\n",
        "plt.plot(epochs_range, acc_history_7x7, marker='x', linestyle='--', label='VGG16 (7x7 Conv Customization)')\n",
        "plt.title('Train Accuracy Comparison', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Train Accuracy (%)', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True)\n",
        "\n",
        "# 4. 최종 테스트 정확도 비교\n",
        "plt.subplot(2, 2, 4)\n",
        "test_accuracies_values = [test_accuracy_3x3, test_accuracy_7x7]\n",
        "bars_test_acc = plt.bar(model_labels, test_accuracies_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('Test Accuracy Comparison', fontsize=14)\n",
        "plt.ylabel('정확도 (%)', fontsize=12)\n",
        "plt.ylim(0, 100) # Y축 범위: 0에서 100 (정확도)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_test_acc:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1.0, f'{yval:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 플롯들이 겹치지 않도록 레이아웃 조정\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SzDrLaWf70YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실험3:** GoogLeNet Inception Module의 1x1 conv에서 차원 축소는 왜 중요한가?"
      ],
      "metadata": {
        "id": "IoBFfufpP1MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, Union, Any, List\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2), # 5x5 conv, padding=2\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 maxpool -> 1x1 conv branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3) # 원본 논문 그림 참조 (output 4x4xChannels)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # 논문에서는 이 conv 출력을 4x4x128로 기술\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 1024) # 4*4*128 = 2048. torchvision은 2048 사용.\n",
        "                                               # 논문 그림에는 4x4x128을 flatten하고 FC로.\n",
        "                                               # torchvision 구현은 AdaptiveAvgPool2d((1,1)) 쓰고 128을 fc1에 넣음.\n",
        "                                               # 여기서는 논문 그림의 크기를 최대한 따름.\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.7) # 논문은 0.7, torchvision은 0.2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # N x C x H x W\n",
        "        x = self.avgpool(x)\n",
        "        # N x C x 4 x 4 (for 14x14 input to aux head)\n",
        "        x = self.conv(x)\n",
        "        # N x 128 x 4 x 4\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x (128*4*4)\n",
        "        x = F.relu(self.fc1(x), inplace=True)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        # N x num_classes\n",
        "        return x\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, aux_logits=False, dropout=0.2, dropout_aux=0.7):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        # Stem: Conv -> Pool -> LRN -> Conv_reduce -> Conv -> LRN -> Pool\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ) # 224x224 -> 112x112\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 112x112 -> 56x56\n",
        "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "\n",
        "        self.conv2_reduce = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 56x56 -> 28x28\n",
        "\n",
        "        # Inception modules\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # out: 256\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) # out: 480\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 28x28 -> 14x14\n",
        "\n",
        "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)   # out: 512\n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(512, num_classes) # 4a output\n",
        "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)  # out: 512\n",
        "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)  # out: 512\n",
        "        if self.aux_logits:\n",
        "            self.aux2 = InceptionAux(528, num_classes) # 4d output (다음 inception4d의 out_channels=528)\n",
        "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)  # out: 528\n",
        "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128) # out: 832\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128) # out: 832\n",
        "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128) # out: 1024\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
        "        # N x 3 x 224 x 224\n",
        "        x = self.conv1(x) # -> N x 64 x 112 x 112\n",
        "        x = self.maxpool1(x) # -> N x 64 x 56 x 56\n",
        "        x = self.lrn1(x)\n",
        "        x = self.conv2_reduce(x) # -> N x 64 x 56 x 56\n",
        "        x = self.conv2(x) # -> N x 192 x 56 x 56\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x) # -> N x 192 x 28 x 28\n",
        "\n",
        "        x = self.inception3a(x) # -> N x 256 x 28 x 28\n",
        "        x = self.inception3b(x) # -> N x 480 x 28 x 28\n",
        "        x = self.maxpool3(x) # -> N x 480 x 14 x 14\n",
        "\n",
        "        x = self.inception4a(x) # -> N x 512 x 14 x 14\n",
        "        aux1: Optional[torch.Tensor] = None\n",
        "        if self.aux_logits and self.training: # Training때만 적용\n",
        "            aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x) # -> N x 512 x 14 x 14\n",
        "        x = self.inception4c(x) # -> N x 512 x 14 x 14\n",
        "        x = self.inception4d(x) # -> N x 528 x 14 x 14\n",
        "        aux2: Optional[torch.Tensor] = None\n",
        "        if self.aux_logits and self.training: # Training때만 적용\n",
        "            aux2 = self.aux2(x) # inception4d의 출력을 aux2에 전달\n",
        "\n",
        "        x = self.inception4e(x) # -> N x 832 x 14 x 14\n",
        "        x = self.maxpool4(x) # -> N x 832 x 7 x 7\n",
        "\n",
        "        x = self.inception5a(x) # -> N x 832 x 7 x 7\n",
        "        x = self.inception5b(x) # -> N x 1024 x 7 x 7\n",
        "\n",
        "        x = self.avgpool(x) # -> N x 1024 x 1 x 1\n",
        "        x = torch.flatten(x, 1) # -> N x 1024\n",
        "        x = self.dropout(x)\n",
        "        main_output = self.fc(x) # -> N x num_classes\n",
        "\n",
        "        if self.aux_logits and self.training: # Training때만 적용\n",
        "            return main_output, aux1, aux2\n",
        "        return main_output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wZI3UKYHQKwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 새로운 Inception 모듈 (1x1 차원 축소 제거) ---\n",
        "class Inception_NoBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3, ch5x5):\n",
        "        super(Inception_NoBottleneck, self).__init__()\n",
        "\n",
        "        # Branch 1: 1x1 conv (원본과 동일)\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Branch 2: 3x3 conv (1x1 차원 축소 conv 제거)\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Branch 3: 5x5 conv (1x1 차원 축소 conv 제거)\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Branch 4: 3x3 maxpool (1x1 차원 축소 conv 제거)\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1_out = self.branch1(x)\n",
        "        branch2_out = self.branch2(x)\n",
        "        branch3_out = self.branch3(x)\n",
        "        branch4_out = self.branch4(x)\n",
        "        outputs = [branch1_out, branch2_out, branch3_out, branch4_out]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "# Inception Module에서 1x1 conv 차원축소 Layer 없앤 Custom 버전의 GoogLeNet\n",
        "class GoogLeNet_Custom(nn.Module):\n",
        "    def __init__(self, num_classes=10, aux_logits=False, dropout=0.2, dropout_aux=0.7):\n",
        "        super(GoogLeNet_Custom, self).__init__()\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        # Stem (원본 GoogLeNet과 동일)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        self.conv2_reduce = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        # Modified Inception modules using Inception_NoBottleneck\n",
        "\n",
        "        current_in_channels = 192 # After conv2 and maxpool2\n",
        "        self.inception3a = Inception_NoBottleneck(current_in_channels, 64, 128, 32)\n",
        "        current_in_channels = 64 + 128 + 32 + current_in_channels # 416 (64+128+32+192)\n",
        "        self.inception3b = Inception_NoBottleneck(current_in_channels, 128, 192, 96)\n",
        "        current_in_channels = 128 + 192 + 96 + current_in_channels # 832 (128+192+96+416)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = Inception_NoBottleneck(current_in_channels, 192, 208, 48)\n",
        "        current_in_channels = 192 + 208 + 48 + current_in_channels # 1280 (192+208+48+832)\n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(current_in_channels, num_classes)\n",
        "        self.inception4b = Inception_NoBottleneck(current_in_channels, 160, 224, 64)\n",
        "        current_in_channels = 160 + 224 + 64 + current_in_channels # 1728 (160+224+64+1280)\n",
        "        self.inception4c = Inception_NoBottleneck(current_in_channels, 128, 256, 64)\n",
        "        current_in_channels = 128 + 256 + 64 + current_in_channels # 2176 (128+256+64+1728)\n",
        "        self.inception4d = Inception_NoBottleneck(current_in_channels, 112, 288, 64)\n",
        "        current_in_channels = 112 + 288 + 64 + current_in_channels # 2640 (112+288+64+2176)\n",
        "        if self.aux_logits:\n",
        "            self.aux2 = InceptionAux(current_in_channels, num_classes)\n",
        "        self.inception4e = Inception_NoBottleneck(current_in_channels, 256, 320, 128)\n",
        "        current_in_channels = 256 + 320 + 128 + current_in_channels # 3344 (256+320+128+2640)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = Inception_NoBottleneck(current_in_channels, 256, 320, 128)\n",
        "        current_in_channels = 256 + 320 + 128 + current_in_channels # 4048 (256+320+128+3344)\n",
        "        self.inception5b = Inception_NoBottleneck(current_in_channels, 384, 384, 128)\n",
        "        current_in_channels = 384 + 384 + 128 + current_in_channels # 4944 (384+384+128+4048)\n",
        "\n",
        "        # Classifier (원본 GoogLeNet과 동일)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(current_in_channels, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Any: # 반환 타입 Any로 단순화 (Tuple 또는 Tensor)\n",
        "        # Stem\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.lrn1(x)\n",
        "        x = self.conv2_reduce(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Inception blocks\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        aux1: Optional[torch.Tensor] = None\n",
        "        if self.aux_logits and self.training:\n",
        "            aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        aux2: Optional[torch.Tensor] = None\n",
        "        if self.aux_logits and self.training:\n",
        "            aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        main_output = self.fc(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            return main_output, aux1, aux2\n",
        "        return main_output"
      ],
      "metadata": {
        "id": "YewIxQescYJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"GoogLeNet 원본 모델 학습\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "model_googlenet = GoogLeNet(aux_logits=False).to(DEVICE) # 표준 GoogleNet\n",
        "print(model_googlenet)\n",
        "\n",
        "# 1. 파라미터 수 계산\n",
        "total_params_googlenet = sum(p.numel() for p in model_googlenet.parameters() if p.requires_grad)\n",
        "print(f\"\\n표준 GoogLeNet 파라미터 수: {total_params_googlenet:,}\")\n",
        "\n",
        "# 2. 학습 연산 시간 측정\n",
        "print(f\"\\n\\n학습 시작\")\n",
        "start_time_googlenet = time.time()\n",
        "loss_history_googlenet, acc_history_googlenet = Train(model_googlenet, train_DL, criterion)\n",
        "end_time_googlenet = time.time()\n",
        "training_time_googlenet = end_time_googlenet - start_time_googlenet\n",
        "print(f\"\\n표준 GoogLeNet 총 학습 시간: {training_time_googlenet:.2f} 초\")\n",
        "\n",
        "# 3. 분류 성능 평가\n",
        "print(\"\\n표준 GoogleNet 테스트\")\n",
        "test_accuracy_googlenet = Test(model_googlenet, test_DL)"
      ],
      "metadata": {
        "id": "CiarKVsWo4Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"GoogLeNet_Custom 모델 학습\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "model_googlenet_custom = GoogLeNet_Custom(aux_logits=False).to(DEVICE) # 1x1 Conv 차원축소 Bottleneck Layer 제외한 GoogleNet_Custom\n",
        "print(model_googlenet_custom)\n",
        "\n",
        "# 1. 파라미터 수 계산\n",
        "total_params_googlenet_custom = sum(p.numel() for p in model_googlenet_custom.parameters() if p.requires_grad)\n",
        "print(f\"\\nGoogLeNet_Custom 파라미터 수: {total_params_googlenet_custom:,}\")\n",
        "\n",
        "# 2. 학습 연산 시간 측정\n",
        "print(f\"\\n\\n학습 시작\")\n",
        "start_time_googlenet_custom = time.time()\n",
        "loss_history_googlenet_custom, acc_history_googlenet_custom = Train(model_googlenet_custom, train_DL, criterion)\n",
        "end_time_googlenet_custom = time.time()\n",
        "training_time_googlenet_custom = end_time_googlenet_custom - start_time_googlenet_custom\n",
        "print(f\"\\GoogLeNet_Custom 총 학습 시간: {training_time_googlenet_custom:.2f} 초\")\n",
        "\n",
        "# 3. 분류 성능 평가\n",
        "print(\"\\nGoogleNet_Custom 테스트\")\n",
        "test_accuracy_googlenet_custom = Test(model_googlenet_custom, test_DL)"
      ],
      "metadata": {
        "id": "yvASnCXbZrvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 플롯 생성\n",
        "epochs_range = range(1, EPOCH + 1)\n",
        "model_labels = ['Vanila GoogLeNet', 'GoogLeNet(No Bottleneck)']\n",
        "\n",
        "plt.figure(figsize=(18, 12)) # 4개의 플롯을 위한 크기 조정\n",
        "\n",
        "# 1. 파라미터 수 비교\n",
        "plt.subplot(3, 2, 1)\n",
        "params_values = [total_params_googlenet, total_params_googlenet_custom]\n",
        "bars_params = plt.bar(model_labels, params_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('모델 파라미터 수 비교', fontsize=14)\n",
        "plt.ylabel('파라미터 수', fontsize=12)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_params:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + max(params_values)*0.01, f'{int(yval):,}', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 2. 학습 시간 비교\n",
        "plt.subplot(3, 2, 2)\n",
        "time_values = [training_time_googlenet, training_time_googlenet_custom]\n",
        "bars_time = plt.bar(model_labels, time_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('Train Time Comparison', fontsize=14)\n",
        "plt.ylabel('시간 (sec)', fontsize=12)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_time:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + max(time_values)*0.01, f'{yval:.2f}s', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 3. 에폭별 학습 정확도 비교\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.plot(epochs_range, acc_history_3x3, marker='o', linestyle='-', label='Vanila GoogLeNet')\n",
        "plt.plot(epochs_range, acc_history_7x7, marker='x', linestyle='--', label='Googlenet(No Bottleneck)')\n",
        "plt.title('Train Accuracy Comparison', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Train Accuracy (%)', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True)\n",
        "\n",
        "# 4. 최종 테스트 정확도 비교\n",
        "plt.subplot(3, 2, 4)\n",
        "test_accuracies_values = [test_accuracy_googlenet, test_accuracy_googlenet_custom]\n",
        "bars_test_acc = plt.bar(model_labels, test_accuracies_values, color=['skyblue', 'lightcoral'], width=0.5)\n",
        "plt.title('Test Accuracy Comparison', fontsize=14)\n",
        "plt.ylabel('정확도 (%)', fontsize=12)\n",
        "plt.ylim(0, 100) # Y축 범위: 0에서 100 (정확도)\n",
        "plt.xticks(rotation=0, ha='center') # 레이블이 잘 보이도록 설정\n",
        "# 막대 위에 값 표시\n",
        "for bar in bars_test_acc:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1.0, f'{yval:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# 플롯들이 겹치지 않도록 레이아웃 조정\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3aiuo8vpoW0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실험 4:** 깊게 쌓은 Network의 문제점 - 아주 깊게 쌓은 Network의 Gradient와 성능은 어떻게 나타날까? (in VGG, GoogLeNet)"
      ],
      "metadata": {
        "id": "SMk3EaEYp328"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module): # Vanila VGG16\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 14 -> 7\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096), # Block 5의 마지막 Conv2d 출력 채널은 512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "u7YlWzAbMsiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG50(nn.Module): # VGG50 - 47 conv layers + 3 fc layers\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG50, self).__init__()\n",
        "\n",
        "        # Block 1 - 9 conv layers\n",
        "        block1_layers = []\n",
        "        block1_layers.append(nn.Conv2d(3, 64, kernel_size=3, padding=1))\n",
        "        block1_layers.append(nn.ReLU(inplace=True))\n",
        "        for i in range(8):\n",
        "            block1_layers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
        "            block1_layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # Block 2 - 9 conv layers\n",
        "        block2_layers = []\n",
        "        block2_layers.append(nn.Conv2d(64, 128, kernel_size=3, padding=1))\n",
        "        block2_layers.append(nn.ReLU(inplace=True))\n",
        "        for i in range(8):\n",
        "            block2_layers.append(nn.Conv2d(128, 128, kernel_size=3, padding=1))\n",
        "            block2_layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # Block 3 - 9 conv layers\n",
        "        block3_layers = []\n",
        "        block3_layers.append(nn.Conv2d(128, 256, kernel_size=3, padding=1))\n",
        "        block3_layers.append(nn.ReLU(inplace=True))\n",
        "        for i in range(8):\n",
        "            block3_layers.append(nn.Conv2d(256, 256, kernel_size=3, padding=1))\n",
        "            block3_layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # Block 4 - 10 conv layers\n",
        "        block4_layers = []\n",
        "        block4_layers.append(nn.Conv2d(256, 512, kernel_size=3, padding=1))\n",
        "        block4_layers.append(nn.ReLU(inplace=True))\n",
        "        for i in range(9):\n",
        "            block4_layers.append(nn.Conv2d(512, 512, kernel_size=3, padding=1))\n",
        "            block4_layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # Block 5 - 10 conv layers\n",
        "        block5_layers = []\n",
        "        for i in range(10):\n",
        "            block5_layers.append(nn.Conv2d(512, 512, kernel_size=3, padding=1))\n",
        "            block5_layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            *block1_layers,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 224 -> 112\n",
        "            *block2_layers,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 112 -> 56\n",
        "            *block3_layers,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 56 -> 28\n",
        "            *block4_layers,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 28 -> 14\n",
        "            *block5_layers,\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 14 -> 7\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096), # Block 5의 마지막 Conv2d 출력 채널은 512\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_hjqi-DKHLB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, Union, Any, List\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2), # 5x5 conv, padding=2\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 maxpool -> 1x1 conv branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module): # Standard GoogLeNet - 22layers (stem(3) + 9 inception module(18) + fc(1))\n",
        "    def __init__(self, num_classes=10, dropout=0.2):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "\n",
        "        # Stem: Conv -> Pool -> LRN -> Conv_reduce -> Conv -> LRN -> Pool\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ) # 224x224 -> 112x112\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 112x112 -> 56x56\n",
        "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "\n",
        "        self.conv2_reduce = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 56x56 -> 28x28\n",
        "\n",
        "        # Inception modules\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # out: 256\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) # out: 480\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 28x28 -> 14x14\n",
        "\n",
        "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)   # out: 512\n",
        "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)  # out: 512\n",
        "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)  # out: 512\n",
        "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)  # out: 528\n",
        "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128) # out: 832\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128) # out: 832\n",
        "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128) # out: 1024\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
        "        # N x 3 x 224 x 224\n",
        "        x = self.conv1(x) # -> N x 64 x 112 x 112\n",
        "        x = self.maxpool1(x) # -> N x 64 x 56 x 56\n",
        "        x = self.lrn1(x)\n",
        "        x = self.conv2_reduce(x) # -> N x 64 x 56 x 56\n",
        "        x = self.conv2(x) # -> N x 192 x 56 x 56\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x) # -> N x 192 x 28 x 28\n",
        "\n",
        "        x = self.inception3a(x) # -> N x 256 x 28 x 28\n",
        "        x = self.inception3b(x) # -> N x 480 x 28 x 28\n",
        "        x = self.maxpool3(x) # -> N x 480 x 14 x 14\n",
        "\n",
        "        x = self.inception4a(x) # -> N x 512 x 14 x 14\n",
        "\n",
        "        x = self.inception4b(x) # -> N x 512 x 14 x 14\n",
        "        x = self.inception4c(x) # -> N x 512 x 14 x 14\n",
        "        x = self.inception4d(x) # -> N x 528 x 14 x 14\n",
        "\n",
        "        x = self.inception4e(x) # -> N x 832 x 14 x 14\n",
        "        x = self.maxpool4(x) # -> N x 832 x 7 x 7\n",
        "\n",
        "        x = self.inception5a(x) # -> N x 832 x 7 x 7\n",
        "        x = self.inception5b(x) # -> N x 1024 x 7 x 7\n",
        "\n",
        "        x = self.avgpool(x) # -> N x 1024 x 1 x 1\n",
        "        x = torch.flatten(x, 1) # -> N x 1024\n",
        "        x = self.dropout(x)\n",
        "        main_output = self.fc(x) # -> N x num_classes\n",
        "\n",
        "        return main_output"
      ],
      "metadata": {
        "id": "TcA-UXHsNR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, Union, Any, List\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2), # 5x5 conv, padding=2\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3x3 maxpool -> 1x1 conv branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class GoogLeNet_50(nn.Module): # GoogLeNet_50 - 50layers (stem(3) + 23 inception module(46) + fc(1))\n",
        "    def __init__(self, num_classes=10, dropout=0.2):\n",
        "        super(GoogLeNet_50, self).__init__()\n",
        "\n",
        "        # Stem: Conv -> Pool -> LRN -> Conv_reduce -> Conv -> LRN -> Pool (3 conv layers)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ) # 224x224 -> 112x112\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 112x112 -> 56x56\n",
        "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "\n",
        "        self.conv2_reduce = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 56x56 -> 28x28\n",
        "\n",
        "        # 23 Inception modules (46 layers)\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # out: 256\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64) # out: 480\n",
        "        self.inception3c = Inception(480, 160, 112, 224, 24, 64, 80) # out: 528\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) # 28x28 -> 14x14\n",
        "\n",
        "        self.inception4a = Inception(528, 192, 96, 208, 16, 48, 112)   # Output: 560\n",
        "        self.inception4b = Inception(560, 192, 128, 256, 24, 64, 128)  # Output: 640\n",
        "        self.inception4c = Inception(640, 224, 144, 288, 32, 64, 128)  # Output: 704\n",
        "        self.inception4d = Inception(704, 224, 160, 320, 32, 80, 128)  # Output: 752\n",
        "        self.inception4e = Inception(752, 256, 160, 320, 40, 80, 160)  # Output: 816\n",
        "        self.inception4f = Inception(816, 256, 192, 384, 40, 96, 160)  # Output: 896\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = Inception(896, 256, 192, 384, 48, 128, 192) # Output: 960\n",
        "        self.inception5b = Inception(960, 320, 192, 384, 48, 128, 192) # Output: 1024\n",
        "        self.inception5c = Inception(1024, 320, 208, 416, 48, 128, 192)# Output: 1056\n",
        "        self.inception5d = Inception(1056, 352, 208, 416, 64, 128, 224)# Output: 1120\n",
        "        self.inception5e = Inception(1120, 352, 224, 448, 64, 128, 224)# Output: 1152\n",
        "        self.inception5f = Inception(1152, 384, 224, 448, 64, 160, 224)# Output: 1216\n",
        "        self.inception5g = Inception(1216, 384, 240, 480, 64, 160, 256)# Output: 1280\n",
        "        self.inception5h = Inception(1280, 416, 240, 480, 80, 160, 256)# Output: 1312\n",
        "\n",
        "        self.inception6a = Inception(1312, 416, 256, 512, 80, 160, 256) # Output: 1344\n",
        "        self.inception6b = Inception(1344, 416, 272, 544, 80, 160, 256) # Output: 1376\n",
        "        self.inception6c = Inception(1376, 448, 272, 544, 80, 160, 256) # Output: 1408\n",
        "        self.inception6d = Inception(1408, 448, 288, 576, 80, 160, 256) # Output: 1440\n",
        "        self.inception6e = Inception(1440, 480, 288, 576, 80, 160, 256) # Output: 1472\n",
        "        self.inception6f = Inception(1472, 480, 304, 608, 96, 192, 256) # Output: 1536\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(1536, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Stem\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.lrn1(x)\n",
        "        x = self.conv2_reduce(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Inception3x\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.inception3c(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # Inception4x\n",
        "        x = self.inception4a(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        x = self.inception4e(x)\n",
        "        x = self.inception4f(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        # Inception5x\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.inception5c(x)\n",
        "        x = self.inception5d(x)\n",
        "        x = self.inception5e(x)\n",
        "        x = self.inception5f(x)\n",
        "        x = self.inception5g(x)\n",
        "        x = self.inception5h(x)\n",
        "\n",
        "        # Inception6x\n",
        "        x = self.inception6a(x)\n",
        "        x = self.inception6b(x)\n",
        "        x = self.inception6c(x)\n",
        "        x = self.inception6d(x)\n",
        "        x = self.inception6e(x)\n",
        "        x = self.inception6f(x)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "qPSgygSoP1v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 코드 짜기"
      ],
      "metadata": {
        "id": "s7rm1Dr_SaoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실험 5:** ResNet - 아무리 깊게 쌓아도 왜 성능이 하락하지 않는가?"
      ],
      "metadata": {
        "id": "bzoHx37dSZ98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Type, List, Callable, Any\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1  # output channels multiplier\n",
        "\n",
        "    def __init__(self, inplanes: int, planes: int, stride: int = 1,\n",
        "                 downsample: nn.Module | None = None) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes: int, planes: int, stride: int = 1,\n",
        "                 downsample: nn.Module | None = None) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block: Type[nn.Module], layers: List[int],\n",
        "                 num_classes: int = 10) -> None:\n",
        "        super().__init__()\n",
        "        self.inplanes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block: Type[nn.Module], planes: int, blocks: int,\n",
        "                    stride: int = 1) -> nn.Sequential:\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers: list[nn.Module] = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "QTxGu1-PSl3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(num_classes: int = 10) -> ResNet:\n",
        "    \"\"\"ResNet‑18 – 2×[2,2,2,2] BasicBlocks\"\"\"\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "\n",
        "def resnet50(num_classes: int = 10) -> ResNet:\n",
        "    \"\"\"ResNet‑50 – 3×[3,4,6,3] Bottleneck blocks\"\"\"\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "\n",
        "def resnet101(num_classes: int = 10) -> ResNet:\n",
        "    \"\"\"ResNet‑101 – 3×[3,4,23,3] Bottleneck blocks\"\"\"\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "5k1YOLt6bgmh",
        "outputId": "6b4880d5-6265-4b49-e758-ce792271f7ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ResNet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c6c1138c5ea5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"ResNet‑18 – 2×[2,2,2,2] BasicBlocks\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ResNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model18 = resnet18()\n",
        "model50 = resnet50()\n",
        "model101 = resnet101()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "jPP5_ZIzbn3y",
        "outputId": "1982badf-c795-4c61-a13b-4591987793a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'resnet18' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-648221bb7945>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel101\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resnet18' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 코드 짜기"
      ],
      "metadata": {
        "id": "SzP75rM5b_rP"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}
